# -*- coding: utf-8 -*-
"""final_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PFyhmJs9li3IM9lqVo3tWSOFct014JqF
"""

import tensorflow as tf
import pandas as pd
import numpy as np 
from sklearn.preprocessing import MinMaxScaler
from keras.models import load_model

from google.colab import drive
drive.mount('/content/drive')

def kalman_filter(z_meas, x_esti, P):
    """Kalman Filter Algorithm for One Variable."""
    # (1) Prediction.
    x_pred = A * x_esti
    P_pred = A * P * A + Q

    # (2) Kalman Gain.
    K = P_pred * H / (H * P_pred * H + R)

    # (3) Estimation.
    x_esti = x_pred + K * (z_meas - H * x_pred)

    # (4) Error Covariance.
    P = P_pred - K * H * P_pred

    return x_esti, P

A = 1
H = 1
Q = 0.00001
R = 0.001



# Look_ahead 조정   20-> 10일치  // 10 -> 5일치 // 6 -> 3일치
look_ahead=20



def make_dataset(data, label, window_size=look_ahead):
    feature_list = []
    label_list = []
    for i in range(len(data) - window_size-20):
        feature_list.append(np.array(data.iloc[i:i+window_size]))
        label_list.append(np.array(label.iloc[i+window_size+20]))
    return np.array(feature_list), np.array(label_list)

#model = load_model('/content/drive/MyDrive/Colab Notebooks/finalTest.h5')




df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Waton/Bank_cell/14_cell.csv')
test_df = df['ResistValue']
x_0 = test_df[0]
P_0 = 1
n_samples = len(test_df)
x_esti, P = None, None
esti_save = np.zeros(n_samples)
x_esti, P = None, None
esti_save = np.zeros(n_samples)
for i in range(n_samples):
    if i == 0:
        x_esti, P = x_0, P_0
    else:
        x_esti, P = kalman_filter(test_df[i], x_esti, P)
        
    esti_save[i] = x_esti

    
# 칼만필터 적용
x_0 = test_df[0]
n_samples=len(test_df)
test_df_re = test_df[:n_samples-look_ahead+20]
x_esti, P = None, None
esti_save = np.zeros(n_samples-look_ahead+20)
for i in range(n_samples-look_ahead):
    if i == 0:
        x_esti, P = x_0, P_0
    else:
        x_esti, P = kalman_filter(test_df_re[i], x_esti, P)
        
    esti_save[i] = x_esti

# fitting
x_train = esti_save
y_train = esti_save
x_train = pd.DataFrame(x_train)
y_train = pd.DataFrame(y_train)
scaler=MinMaxScaler()
x_train = scaler.fit_transform(x_train)
y_train = scaler.fit_transform(y_train)
x_train = pd.DataFrame(x_train)
y_train = pd.DataFrame(y_train)


# Dataset 생성
train_feature, train_label = make_dataset(x_train, y_train, look_ahead)

xhat = train_feature[0]
#predictions = np.zeros((look_ahead, 1))

# Loading Model
model = load_model('/content/drive/MyDrive/Colab Notebooks/finalTest.h5')
prediction = model.predict(np.array([xhat]), batch_size=16)
pred = scaler.inverse_transform(prediction[-1])
actual = test_df[n_samples-look_ahead:].values

# 오차율 = (이론값-측정값)/이론값 * 100
errors=[]
for i in range(look_ahead):
  print(esti_save[i],'| vs |', pred[-1][i])
  errors.append(abs(esti_save[i]-pred[-1][i])/actual[i]*100)
print('평균 오차율(%)', sum(errors)/len(errors))
print(errors)

import matplotlib.pyplot as plt
plt.plot(esti_save[:look_ahead], label='actual(kalman-filter)')
plt.plot(pred[-1][:look_ahead], label='pred')
plt.legend(loc='upper ajleft')
plt.title('actual(k-f) v.s. Estimation ')
plt.xlabel('Time [Day]')
plt.ylabel('ResistValue')

